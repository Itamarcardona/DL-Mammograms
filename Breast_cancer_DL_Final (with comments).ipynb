{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Breast_cancer_DL_Final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CteEXt23gEIP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tensorflow_version 1.x\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDbiVcHjpI8d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# images and labels were saved as numpy files in my private drive so I mount it so I can use it later\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZYpYez0pS2Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#imports\n",
        "from keras.models import model_from_json\n",
        "import numpy as np\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D, Conv3D, GlobalAveragePooling2D\n",
        "from keras import backend as K\n",
        "from keras import optimizers\n",
        "from keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.callbacks import EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
        "from keras import regularizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from collections import Counter\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WcE6G0pBt5x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load data, print data shape to check database size& each class size \n",
        "images=np.load('/content/drive/My Drive/Final_project_breast_cancer/mammos.npy')\n",
        "labels=np.load('/content/drive/My Drive/Final_project_breast_cancer/labels.npy')\n",
        "print(images.shape)\n",
        "print(labels.shape)\n",
        "\n",
        "class0=labels[:,0]\n",
        "class1=labels[:,1]\n",
        "sum0=sum(class0)\n",
        "sum1=sum(class1)\n",
        "print('num of objects in class 0:',sum0,'\\n','num of objects in class 1:', sum1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MWgU7g7B0TD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#filter data to seperate class0 &class data\n",
        "\"\"\"filtering data - class separation\"\"\"\n",
        "def filter(data,labels):\n",
        "  x_c0=[]\n",
        "  x_c1=[]\n",
        "  y_c0=[]\n",
        "  y_c1=[]\n",
        "  for i in range(0,len(data)):\n",
        "    if labels[i,0]==1:\n",
        "      x_c0.append(data[i,:,:,:])\n",
        "      y_c0.append(labels[i,:])\n",
        "    else:\n",
        "      x_c1.append(data[i,:,:,:])\n",
        "      y_c1.append(labels[i,:])\n",
        "  return x_c0,y_c0,x_c1,y_c1\n",
        "\n",
        "class0_data, class0_labels, class1_data, class1_labels=filter(images,labels)\n",
        "class0_data=np.array(class0_data)\n",
        "class0_labels=np.array(class0_labels)\n",
        "class1_data=np.array(class1_data)\n",
        "class1_labels=np.array(class1_labels)\n",
        "#validate filtering\n",
        "print('class0 data shape:', class0_data.shape)\n",
        "print('class0 labels shape:',class0_labels.shape)\n",
        "print('class1 data shape:',class1_data.shape)\n",
        "print('class1 labels shape:',class1_labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZK-AOfaB4y1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get test and val data befor augmenting and get train data after undersampling to balance classes\n",
        "test_data=[*class0_data[:200,:,:,:],*class1_data[:200,:,:,:]]\n",
        "test_label=[*class0_labels[:200,:], *class1_labels[:200,:]]\n",
        "test_data=np.array(test_data)\n",
        "test_label=np.array(test_label)\n",
        "\n",
        "s = np.arange(test_data.shape[0])\n",
        "np.random.shuffle(s)\n",
        "test_data=test_data[s]\n",
        "test_label=test_label[s]\n",
        "\n",
        "val_data=[*class0_data[200:400,:,:,:],*class1_data[200:400,:,:,:]]\n",
        "val_label=[*class0_labels[200:400,:],*class1_labels[200:400,:]]\n",
        "val_data=np.array(val_data)\n",
        "val_label=np.array(val_label)\n",
        "s = np.arange(val_data.shape[0])\n",
        "np.random.shuffle(s)\n",
        "val_data=val_data[s]\n",
        "val_label=val_label[s]\n",
        "print('test_data:' ,test_data.shape)\n",
        "print('test_labels',test_label.shape)\n",
        "\n",
        "print('val data:',val_data.shape)\n",
        "print('val labels:',val_label.shape)\n",
        "\n",
        "class0_data=class0_data[400:927,:,:,:]\n",
        "class0_labels=class0_labels[400:927,:]\n",
        "class1_data=class1_data[400:927,:,:,:]\n",
        "class1_labels=class1_labels[400:927,:]\n",
        "\n",
        "del images,labels,class0,class1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eWvBWRJB8xt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Augmentaion parameters\n",
        "\n",
        "# Define wanted augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    brightness_range=(0.7, 1.3),\n",
        "    rotation_range=15\n",
        "    \n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuY5VPHtCAAB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#class 1 augmentation\n",
        "\n",
        "# Fit on class1\n",
        "datagen.fit(class1_data)\n",
        "\n",
        "# class1 augmentation\n",
        "class1_aug_data=[]\n",
        "class1_aug_labels=[]\n",
        "for i in range (0,10):\n",
        "  for x_batch, y_batch in datagen.flow(class1_data, class1_labels, batch_size=500):\n",
        "    break\n",
        "  class1_aug_data.append(x_batch)\n",
        "  class1_aug_labels.append(y_batch)\n",
        "class1_aug_data=np.array(class1_aug_data)\n",
        "class1_aug_labels=np.array(class1_aug_labels)\n",
        "\n",
        "\n",
        "class1_aug_data=class1_aug_data.reshape(5000,200,200,1)\n",
        "class1_aug_labels=class1_aug_labels.reshape(5000,2)\n",
        "\n",
        "#merge augmentation + original data\n",
        "class1_total_data=[*class1_data,*class1_aug_data]\n",
        "class1_total_labels=[*class1_labels,*class1_aug_labels]\n",
        "class1_total_data=np.array(class1_total_data)\n",
        "class1_total_labels=np.array(class1_total_labels)\n",
        "print('class1 objects&shape after resampling:',class1_total_data.shape)\n",
        "print('class1 label shape after resampling;' ,class1_total_labels.shape)\n",
        "print('\\n class1 images:')\n",
        "\n",
        "#print to vmake sure images were not damaged\n",
        "for j in range(0, 4):\n",
        "  plt.subplot(2,2,1 + j)\n",
        "  plt.imshow(class1_total_data[j].reshape(200, 200), cmap='gray')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcTFIBb5CJ-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del class1_data\n",
        "del class1_aug_data\n",
        "del class1_labels\n",
        "del class1_aug_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHhFoSTsCO7T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#class0 augmentation\n",
        "class0_aug_data=[]\n",
        "class0_aug_labels=[]\n",
        "datagen.fit(class0_data)\n",
        "\n",
        "for i in range(0,10):\n",
        "  for x_batch, y_batch in datagen.flow(class0_data, class0_labels, batch_size=500):\n",
        "    break\n",
        "  class0_aug_data.append(x_batch)\n",
        "  class0_aug_labels.append(y_batch)\n",
        "\n",
        "class0_aug_data=np.array(class0_aug_data)\n",
        "class0_aug_labels=np.array(class0_aug_labels)\n",
        "\n",
        "\n",
        "class0_aug_data=class0_aug_data.reshape(5000,200,200,1)\n",
        "class0_aug_labels=class0_aug_labels.reshape(5000,2)\n",
        "\n",
        "#merge augmentation+original data\n",
        "class0_total_data=[*class0_data,*class0_aug_data]\n",
        "class0_total_labels=[*class0_labels,*class0_aug_labels]\n",
        "class0_total_data=np.array(class0_total_data)\n",
        "class0_total_labels=np.array(class0_total_labels)\n",
        "\n",
        "print('class0 objects&shape after resampling:',class0_total_data.shape)\n",
        "print('class0 label shape after resampling;' ,class0_total_labels.shape)\n",
        "\n",
        "#print some images\n",
        "print('\\n class0 images:')\n",
        "for j in range(0, 4):\n",
        "  plt.subplot(2,2,1 + j)\n",
        "  plt.imshow(class0_aug_data[j].reshape(200, 200), cmap='gray')\n",
        "  plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zFhQsgWPswv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del x_batch\n",
        "del y_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-1QtXbjCUX4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del class0_data\n",
        "del class0_aug_data\n",
        "del class0_labels\n",
        "del class0_aug_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TJKEbfaCVEB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#combine data to train set\n",
        "train_data=[*class0_total_data ,*class1_total_data]\n",
        "train_labels=[*class0_total_labels, *class1_total_labels]\n",
        "train_data=np.array(train_data)\n",
        "train_labels=np.array(train_labels)\n",
        "\n",
        "print(train_data.shape)\n",
        "print(train_labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhiXQDi7CZXY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del class0_total_data\n",
        "del class0_total_labels\n",
        "del class1_total_data\n",
        "del class1_total_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxmNA9HWCb5I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#shuffle train set and print shape + amount of data in each class (to make sure amount is expected and balanced)\n",
        "s = np.arange(train_data.shape[0])\n",
        "np.random.shuffle(s)\n",
        "train_data=train_data[s]\n",
        "train_labels=train_labels[s]\n",
        "\n",
        "train_labels=np.array(train_labels)\n",
        "train_data=np.array(train_data)\n",
        "print('balanced data shape:', train_data.shape)\n",
        "print('combined label shape:', train_labels.shape)\n",
        "\n",
        "cls0=train_labels[:,0]\n",
        "cls1=train_labels[:,1]\n",
        "sum0=sum(cls0)\n",
        "sum1=sum(cls1)\n",
        "print('\\n','num of objects in class 0:',sum0)\n",
        "print(' num of objects in class 1:', sum1)\n",
        "\n",
        "print(train_labels)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0_XbwtUCoYK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#validate images are intact in all sets\n",
        "print('data examples')\n",
        "\n",
        "train_im=train_data[1298,:,:,:].reshape(200,200)\n",
        "val_im=val_data[190,:,:,:].reshape(200,200)\n",
        "test_im=test_data[380,:,:,:].reshape(200,200)\n",
        "\n",
        "plt.subplot(131)\n",
        "plt.imshow(train_im, cmap='gray')\n",
        "plt.title('Train image')\n",
        "plt.subplot(132)\n",
        "plt.imshow(val_im, cmap='gray')\n",
        "plt.title('val image')\n",
        "plt.subplot(133)\n",
        "plt.imshow(test_im, cmap='gray')\n",
        "plt.title('Test image')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbfYwm0g-zuU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model parameters\n",
        "\n",
        "batch_size = 32\n",
        "num_classes = 2\n",
        "epochs = 35\n",
        "beta_1=0.9\n",
        "beta_2=0.999\n",
        "epsilon=10e-8\n",
        "reg_value= 1e-3\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 200, 200\n",
        "\n",
        "train_data = train_data.astype('float32')\n",
        "test_data = test_data.astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_P2NUTeRtNeh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#this block is Transfer learning network imports. to prevent importing all networks each time use case to choose which network to import\n",
        "case=2\n",
        "#look at cases for desired net\n",
        "##############################################\n",
        "if (case==1):\n",
        "  from keras.applications import vgg16\n",
        "  vgg16=vgg16.VGG16(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(200,200,3)\n",
        "  )\n",
        "############################################# \n",
        "if (case==2):\n",
        "  from keras.applications import densenet\n",
        "  dense201=densenet.DenseNet201(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(200,200,3)\n",
        "    \n",
        "  ) \n",
        "  dense169=densenet.DenseNet169(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(200,200,3)\n",
        "  )\n",
        "  dense121=densenet.DenseNet121(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(200,200,3)\n",
        "  ) \n",
        "###############################################\n",
        "if case==3:\n",
        "  from keras.applications import inception_v3\n",
        "  V3=inception_v3.InceptionV3(\n",
        "      weights='imagenet',\n",
        "      include_top=False,\n",
        "      input_shape=(200,200,3)\n",
        "  )\n",
        "###########################################\n",
        "if case==4:\n",
        "  from keras.applications import xception\n",
        "  XCEPT=xception.Xception(\n",
        "      weights='imagenet',\n",
        "      include_top=False,\n",
        "      input_shape=(200,200,3)\n",
        ")\n",
        "##########################################\n",
        "if case ==5:\n",
        "  from keras.applications import vgg19\n",
        "  vgg19=vgg19.VGG19(\n",
        "      weights='imagenet',\n",
        "      include_top=False,\n",
        "      input_shape=(200,200,3)\n",
        "  )\n",
        "#####################################\n",
        "if case==6:\n",
        "  from keras.applications import resnet\n",
        "  res50=resnet.ResNet50(\n",
        "      weights='imagenet',\n",
        "      include_top=False,\n",
        "      input_shape=(200,200,3)\n",
        "  )\n",
        "  res101=resnet.ResNet101(\n",
        "      weights='imagenet',\n",
        "      include_top=False,\n",
        "      input_shape=(200,200,3)\n",
        "  )\n",
        "  res152=resnet.ResNet152(\n",
        "      weights='imagenet',\n",
        "      include_top=False,\n",
        "      input_shape=(200,200,3)\n",
        "  )\n",
        "#########################################\n",
        "if case==7:\n",
        "  from keras.applications import resnet_v2\n",
        "  res50V2=resnet_v2.ResNet50V2(\n",
        "      weights='imagenet',\n",
        "      include_top=False,\n",
        "      input_shape=(200,200,3)\n",
        "  )\n",
        "  res101V2=resnet_v2.ResNet101V2(\n",
        "      weights='imagenet',\n",
        "      include_top=False,\n",
        "      input_shape=(200,200,3)\n",
        "  )\n",
        "  res152V2=resnet_v2.ResNet152V2(\n",
        "      weights='imagenet',\n",
        "      include_top=False,\n",
        "      input_shape=(200,200,3)\n",
        "  ) \n",
        "#######################################\n",
        "if case==8:\n",
        "  from keras.applications import inception_resnet_v2\n",
        "  V2=inception_resnet_v2.InceptionResNetV2(\n",
        "      weights='imagenet',\n",
        "      include_top=False,\n",
        "      input_shape=(200,200,3)\n",
        "  )\n",
        "#######################################\n",
        "if case==9:\n",
        "  from keras.applications import mobilenet\n",
        "  mobile=mobilenet.MobileNet(\n",
        "      weights='imagenet',\n",
        "      include_top=False,\n",
        "      input_shape=(200,200,3)\n",
        "  )\n",
        "###################################\n",
        "if case==10:\n",
        "  from keras.applications import mobilenet_v2\n",
        "  mobile=mobilenet_v2.MobileNetV2(\n",
        "      weights='imagenet',\n",
        "      include_top=False,\n",
        "      input_shape=(200,200,3)\n",
        "  )\n",
        "######################################\n",
        "if case==11:\n",
        "  from keras.applications import nasnet\n",
        "  nas_l=nasnet.NASNetLarge(\n",
        "        weights=None,\n",
        "        include_top=False,\n",
        "        input_shape=(200,200,3)\n",
        "    )\n",
        "  \n",
        "  nas_m=nasnet.NASNetMobile(\n",
        "        weights=None,\n",
        "        include_top=False,\n",
        "        input_shape=(200,200,3)\n",
        "    )\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgVWYdGUo6Pa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this block decides which layers in TL network will train\n",
        "print(\"Number of layers in the base model: \", len(dense201.layers))\n",
        "for layer in dense201.layers:\n",
        "  layers.trainable = False\n",
        "for layer in dense201.layers[358:]:\n",
        "  layer.trainable =  True\n",
        "for layer in dense201.layers[350:362]:\n",
        "  print(layer.trainable)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nj1wDw4dNKtR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr=8e-5\n",
        "from keras.layers import AveragePooling2D\n",
        "adam = optimizers.Adam(lr=lr, beta_1=beta_1, beta_2=beta_2, epsilon=epsilon)\n",
        "# callbacks - stopping stops while val acc does not increase after 7 iter. reduceLR lowers Learning rate if val loss is not decreasing\n",
        "stopping=keras.callbacks.callbacks.EarlyStopping(monitor='val_acc', min_delta=0.005, patience=7, mode='max', baseline=0.7,restore_best_weights=True)\n",
        "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.75, patience=7,\n",
        "                      min_delta=0.005, mode='min', verbose=1)\n",
        "callbacks_list = [reduceLROnPlat, stopping]\n",
        "\n",
        "#model architecture\n",
        "def build_model(backbone, lr=8e-5):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(3, (1,1), padding='same', kernel_initializer='ones',trainable=False))\n",
        "    model.add(backbone)\n",
        "    model.add(layers.GlobalAveragePooling2D())\n",
        "    model.add(layers.Dropout(0.6))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(Dense(8, kernel_regularizer=regularizers.l1(reg_value*10), activation='relu'))\n",
        "    model.add(Dropout(0.6))\n",
        "    model.add(Dense(4, activation='relu',trainable=False))\n",
        "    model.add(Dropout(0.6))\n",
        "    model.add(layers.Dense(2, kernel_regularizer=regularizers.l1(reg_value*10), activation='softmax'))\n",
        "    \n",
        "    model.compile(\n",
        "        loss='categorical_crossentropy',\n",
        "        optimizer=adam,\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# choose TL network (I used dense201)\n",
        "model = build_model(dense201,lr = 8e-5)\n",
        "\n",
        "#run training\n",
        "history = model.fit(train_data, train_labels,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          callbacks=callbacks_list,\n",
        "         validation_data = (val_data, val_label))\n",
        "\n",
        "#print train&val loss graph\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show(); plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2E9UaZi7Z1q0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print model architecture+ num of parameters\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uD3hqeFbIUdL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# confusion matrix function\n",
        "import itertools\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        normed_cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        normed_cm = normed_cm*100;\n",
        "        print(\"Normalized confusion matrix\")\n",
        "        print(normed_cm)\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    plt.figure(figsize=(15,15))\n",
        "    plt.imshow(normed_cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j,i, format(normed_cm[i, j], fmt)+'%\\n('+(format(cm[i, j], 'd'))+')',\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.gcf().subplots_adjust(bottom=0.3)\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BO2iTSZrChH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print validation set confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "val_pred = model.predict(val_data)\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(np.argmax(val_label,axis=1), np.argmax(np.round(val_pred),axis=1));\n",
        "labels = ['class ' + str(i) for i in range(num_classes)] \n",
        "plot_confusion_matrix(cm,labels,title='Confusion Matrix',normalize=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAV2wuuv4zMr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print test score\n",
        "#####################################################\n",
        "score = model.evaluate(test_data, test_label, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "####################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXr3F4pTrO8f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print test confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "test_pred = model.predict(test_data)\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(np.argmax(test_label,axis=1), np.argmax(np.round(test_pred),axis=1));\n",
        "labels = ['class ' + str(i) for i in range(num_classes)] \n",
        "plot_confusion_matrix(cm,labels,title='Confusion Matrix',normalize=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzgxfUiSFjNX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Data for ROC\n",
        "test_prob=model.predict_proba(test_data)\n",
        "y_t=test_label[:,0]\n",
        "y_p=test_prob[:,0]\n",
        "print('y_t shape:', y_t.shape)\n",
        "print('y_p shape:', y_p.shape)\n",
        "\n",
        "print('y_train shape:', y_t.shape)\n",
        "print('y_test shape:', y_p.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYiiRiB5Aiw2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print ROC curve\n",
        "from sklearn.metrics import roc_curve,roc_auc_score\n",
        "[fpr,tpr,thresholds] = roc_curve ( y_t , y_p)\n",
        "\n",
        "def plot_roc_curve(fpr,tpr): \n",
        "  plt.plot(fpr,tpr,'--') \n",
        "  plt.axis([0,1,0,1]) \n",
        "  plt.xlabel('False Positive Rate') \n",
        "  plt.ylabel('True Positive Rate') \n",
        "  plt.show()    \n",
        "  \n",
        "plot_roc_curve (fpr,tpr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPfh2jPg9TvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#AUC calc\n",
        "from sklearn.metrics import roc_auc_score\n",
        "roc_auc_score(y_t,y_p)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}